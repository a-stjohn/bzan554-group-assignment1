{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "# specify the path to the zipped file.\n",
    "os.chdir('/mnt/c/Users/amsj1/OneDrive - University of Tennessee/2nd_year/BZAN554_deep_learning/bzan554-group-assignment1')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-09-19 22:15:47.643162: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-19 22:15:47.643202: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "# function creation cell\n",
    "\n",
    "def parse(path):\n",
    "    \"\"\"\n",
    "    Function to read in the VERY LARGE dataset and yield it as a generator for\n",
    "    memory efficiency. Takes one argument which is the path to the file being\n",
    "    read in. This path is set abose using 'os.chdir'.\n",
    "    \"\"\"\n",
    "    with gzip.open(path, 'rb') as g:\n",
    "        for l in g:\n",
    "            yield eval(l)\n",
    "\n",
    "def yield_columns():\n",
    "    \"\"\"\n",
    "    Parse the large data set and return a generator of a tuple with X\n",
    "    (product title) and Y (product categories). Each item in the generator is\n",
    "    a numpy array. Column X is at postion 0 and column Y is at position 1.\n",
    "\n",
    "    For example, to access X (product title), the code would be\n",
    "    `next(yield_columns())[0]`.\n",
    "    \"\"\"\n",
    "    for d in parse('meta_Clothing_Shoes_and_Jewelry.json.gz'):\n",
    "        X = np.array(d['title'])\n",
    "        Y = np.array(list(set(d['category'])))\n",
    "\n",
    "        yield X, Y"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# set up model architecture\n",
    "inputs = tf.keras.layers.Input(shape = (1,))\n",
    "hidden1 = tf.keras.layers.Dense(\n",
    "    units = 2,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden1'\n",
    ")(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(\n",
    "    units = 2,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden2'\n",
    ")(hidden1)\n",
    "output = tf.keras.layers.Dense(\n",
    "    units = 1,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'output'\n",
    ")(hidden2)\n",
    "\n",
    "# create & compile the model\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for i in range(1000): # number of epochs\n",
    "    for j in yield_columns(): # number of instances\n",
    "        model.fit(\n",
    "            x=j[0],\n",
    "            y=j[1],\n",
    "            epochs=1,\n",
    "            batch_size=1\n",
    "        )"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}