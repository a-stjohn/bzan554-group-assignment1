{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import re\n",
    "\n",
    "# specify the path to the zipped file.\n",
    "os.chdir('/mnt/c/Users/amsj1/OneDrive - University of Tennessee/2nd_year/BZAN554_deep_learning/bzan554-group-assignment1')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def parse(path):\n",
    "    \"\"\"\n",
    "    Function to read in the VERY LARGE dataset and yield it as a generator for\n",
    "    memory efficiency. Takes one argument which is the path to the file being\n",
    "    read in. This path is set abose using 'os.chdir'.\n",
    "    \"\"\"\n",
    "    with gzip.open(path, 'rb') as g:\n",
    "        for l in g:\n",
    "            yield eval(l)\n",
    "\n",
    "#######################################################################\n",
    "# Basically load in some data to make lookup tables for the sequentially\n",
    "# learning part\n",
    "#######################################################################\n",
    "lookup_X = []\n",
    "Y_raw = []\n",
    "counter = 0\n",
    "for d in parse('meta_Clothing_Shoes_and_Jewelry.json.gz'):\n",
    "    counter += 1\n",
    "    # X_raw.append(d['title'])\n",
    "    X_raw = np.array(d['title'])\n",
    "    Y_raw.append(d['category'])\n",
    "\n",
    "    X_words = [words for words in str(X_raw).lower().split()]\n",
    "    lookup_X.extend(X_words)\n",
    "\n",
    "    if counter == 1000:\n",
    "        break\n",
    "\n",
    "# flatten the Y list of lists\n",
    "flat_Y = [category for subcat in Y_raw for category in subcat]\n",
    "# uniquefy it\n",
    "unique_Y = np.unique(np.array(flat_Y))\n",
    "\n",
    "# look up for Y\n",
    "lookup_Y = []\n",
    "lookup_Y.extend([category for category in unique_Y])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#######################################################################\n",
    "# Set up the simpole model architecture\n",
    "#######################################################################\n",
    "inputs = tf.keras.layers.Input(shape = (len(lookup_X),))\n",
    "hidden1 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_X),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden1'\n",
    ")(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden2'\n",
    ")(hidden1)\n",
    "output = tf.keras.layers.Dense(\n",
    "    units = len(unique_Y),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'output'\n",
    ")(hidden2)\n",
    "\n",
    "#######################################################################\n",
    "# create & compile the simple model\n",
    "#######################################################################\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate = 0.001),\n",
    "    metrics=[tf.keras.metrics.Accuracy()]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#######################################################################\n",
    "# Set up the complex model architecture\n",
    "# NOTE: This was ran on Dan's machine... so variable names are the same\n",
    "# and will be overwritten\n",
    "#######################################################################\n",
    "inputs = tf.keras.layers.Input(shape = (len(lookup_X),))\n",
    "hidden1 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_X),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden1'\n",
    ")(inputs)\n",
    "hidden2 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden2'\n",
    ")(hidden1)\n",
    "hidden3 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y)*2,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden3'\n",
    ")(hidden2)\n",
    "hidden4 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y)*2,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden4'\n",
    ")(hidden3)\n",
    "hidden5 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y)*4,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden5'\n",
    ")(hidden4)\n",
    "hidden6 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y)*4,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden6'\n",
    ")(hidden5)\n",
    "hidden7 = tf.keras.layers.Dense(\n",
    "    units = len(lookup_Y)*4,\n",
    "    activation = 'sigmoid',\n",
    "    name = 'hidden7'\n",
    ")(hidden6)\n",
    "output = tf.keras.layers.Dense(\n",
    "    units = len(unique_Y),\n",
    "    activation = 'sigmoid',\n",
    "    name = 'output'\n",
    ")(hidden7)\n",
    "\n",
    "#######################################################################\n",
    "# create & compile the complex model\n",
    "#######################################################################\n",
    "model = tf.keras.Model(inputs = inputs, outputs = output)\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate = 0.001)\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#######################################################################\n",
    "# Big boy model learning time\n",
    "#######################################################################\n",
    "for i in range(10): # number of epochs\n",
    "    print(f'Epoch number: {i}')\n",
    "    counter = 0\n",
    "    for d in parse('meta_Clothing_Shoes_and_Jewelry.json.gz'): # instances\n",
    "        counter += 1\n",
    "        X_raw = np.array(d['title'])\n",
    "        Y_raw = np.array(d['category'])\n",
    "\n",
    "        ###############################################\n",
    "        # logic for the X hot-one-encoded stuff\n",
    "        ###############################################\n",
    "        # split the titles into words and lowercase\n",
    "        # words = word.lower().split()\n",
    "        X_words = [words for words in str(X_raw).lower().split()]\n",
    "\n",
    "        # Get final binary stuff for X\n",
    "        X_indices = np.where(np.isin(lookup_X, X_words))\n",
    "        X_final = np.zeros(len(lookup_X))\n",
    "        X_final[X_indices] = 1\n",
    "        X_final = X_final.reshape(1, len(X_final))\n",
    "\n",
    "        ###############################################\n",
    "        # logic for the Y hot-one-encoded stuff\n",
    "        ###############################################\n",
    "        Y_indices = np.where(np.isin(lookup_Y, unique_Y))\n",
    "        Y_final = np.zeros(len(lookup_Y))\n",
    "        Y_final[Y_indices] = 1\n",
    "        Y_final = Y_final.reshape(1, len(Y_final))\n",
    "\n",
    "        ###############################################\n",
    "        # Finallllyyyyy fit the freakin model\n",
    "        ###############################################\n",
    "        model.fit(x=X_final,y=Y_final,epochs=1,batch_size=1)\n",
    "\n",
    "        if counter == 1000:\n",
    "            break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# overall predictions\n",
    "yhat = model.predict(x=X_final)\n",
    "\n",
    "# make copy and get out the indices of the top 5 probabilities\n",
    "yhat_copy = yhat.copy()\n",
    "result_ind = np.argpartition(yhat_copy, -5)[0][-5:]\n",
    "result_ind\n",
    "\n",
    "# Get the categories and their highest probability\n",
    "np.array(unique_Y)[result_ind]\n",
    "yhat_copy[0][result_ind]\n",
    "cats_probs = np.column_stack(\n",
    "    [yhat_copy[0][result_ind],\n",
    "    np.array(unique_Y)[result_ind]]\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}